{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN utilisant Tensorflow\n",
    "####  Python · Données de classification des déchets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,BatchNormalization,Flatten,AvgPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "j'ai rencontré une probléme au niveau d'importation du keras-tuner il faut l'installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "J'ai utilisé ImageDataGenerator pour créer mes ensembles de données de formation, de validation et de test. Pour cela, je dois stocker les images de train, valides et de test dans trois fichiers distincts afin de transmettre ces chemins de fichiers en tant que paramètres à ImageDataGenerator. J'ai également utilisé le tuner keras pour trouver le taux d'apprentissage optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'R']\n"
     ]
    }
   ],
   "source": [
    "path='C:/Users/user/Desktop/datasetOR'\n",
    "target=os.listdir(os.path.join(path,'TRAIN'))\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Je déclare un répertoire dans lequel je stockerai les images train, valides et test. Je déclare trois autres diorectoires dans le nouveau répertoire pour le même.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir='C:/Users/user/Desktop/datasetOR/data'\n",
    "train_path=new_dir+'/train'\n",
    "valid_path=new_dir+'/valid'\n",
    "test_path=new_dir+'/test'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Faire une fonction pour créer ces répertoires (puisqu'ils n'existent pas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir():\n",
    "    if not os.path.isdir(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "        os.makedirs(train_path)\n",
    "        os.makedirs(valid_path)\n",
    "        os.makedirs(test_path)\n",
    "        for label in target:\n",
    "            os.makedirs(os.path.join(train_path,label))\n",
    "            os.makedirs(os.path.join(valid_path,label))\n",
    "            os.makedirs(os.path.join(test_path,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vérifier si les répertoires ont été créés avec succès\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path():\n",
    "    print(f'{new_dir}: {os.path.isdir(new_dir)}')\n",
    "    print(f'{train_path}:{os.path.isdir(train_path)}')\n",
    "    print(f'{valid_path}:{os.path.isdir(valid_path)}')\n",
    "    print(f'{test_path}:{os.path.isdir(test_path)}')\n",
    "    for label in target:\n",
    "        print(f'{os.path.join(train_path,label)}:{os.path.isdir(os.path.join(train_path,label))}')\n",
    "        print(f'{os.path.join(valid_path,label)}:{os.path.isdir(os.path.join(valid_path,label))}')\n",
    "        print(f'{os.path.join(test_path,label)}:{os.path.isdir(os.path.join(test_path,label))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/user/Desktop/datasetOR/data: True\n",
      "C:/Users/user/Desktop/datasetOR/data/train:True\n",
      "C:/Users/user/Desktop/datasetOR/data/valid:True\n",
      "C:/Users/user/Desktop/datasetOR/data/test:True\n",
      "C:/Users/user/Desktop/datasetOR/data/train\\O:True\n",
      "C:/Users/user/Desktop/datasetOR/data/valid\\O:True\n",
      "C:/Users/user/Desktop/datasetOR/data/test\\O:True\n",
      "C:/Users/user/Desktop/datasetOR/data/train\\R:True\n",
      "C:/Users/user/Desktop/datasetOR/data/valid\\R:True\n",
      "C:/Users/user/Desktop/datasetOR/data/test\\R:True\n"
     ]
    }
   ],
   "source": [
    "check_path()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Trouver la taille de l'image, pour connaître la taille d'entrée avec laquelle je travaille\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_size():\n",
    "    image_path=os.path.join(path,'TRAIN/O')\n",
    "    for image in os.listdir(image_path):\n",
    "        img_path=os.path.join(image_path,image)\n",
    "        img=cv2.imread(img_path)\n",
    "        print(img.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "find_image_size()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Configuration de certains paramètres :-\n",
    "\n",
    "1. img_size : la taille à laquelle les images sont redimensionnées\n",
    "2. train_valid_path : le chemin du fichier à partir duquel je vais prendre les images d'entraînement et de validation (tous                           deux à partir de ce chemin)\n",
    "3. testing_path : le chemin du fichier à partir duquel je vais prendre mes images de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=(96,96) \n",
    "batch_size=20\n",
    "epochs=5\n",
    "train_valid_path=path+'/TRAIN' \n",
    "testing_path=path+'/TEST'\n",
    "steps_per_epoch=250"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Trois fonctions pour le chargement des images d'entraînement, de validation et de test respectivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_images(img_per_category=15):\n",
    "    for folder in os.listdir(train_valid_path):\n",
    "        folder_path=os.path.join(train_valid_path,folder)\n",
    "        print(f'Loading training images for {folder}')\n",
    "        train_image_set=random.sample(os.listdir(folder_path),img_per_category)\n",
    "        dest=os.path.join(train_path,folder)\n",
    "        for c in tqdm(train_image_set):\n",
    "            img_path=os.path.join(folder_path,c)\n",
    "            shutil.copy(img_path,dest)\n",
    "def load_valid_images(img_per_category=7):\n",
    "    for folder in os.listdir(train_valid_path):\n",
    "        folder_path=os.path.join(train_valid_path,folder)\n",
    "        print(f'Loading validation images for {folder}')\n",
    "        dest=os.path.join(valid_path,folder)\n",
    "        valid_image_set=random.sample(os.listdir(folder_path),img_per_category)\n",
    "        for c in tqdm(valid_image_set):\n",
    "            img_path=os.path.join(folder_path,c)\n",
    "            shutil.copy(img_path,dest)\n",
    "def load_test_images(img_per_category=10):\n",
    "    for folder in os.listdir(testing_path):\n",
    "        print(f'Loading the testing images for {folder}')\n",
    "        folder_path=os.path.join(testing_path,folder)\n",
    "        dest=os.path.join(test_path,folder)\n",
    "        test_image_set=random.sample(os.listdir(folder_path),img_per_category)\n",
    "        for c in tqdm(test_image_set):\n",
    "            img_path=os.path.join(folder_path,c)\n",
    "            shutil.copy(img_path,dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 253.80it/s]\n",
      " 82%|████████▏ | 14/17 [00:00<00:00, 131.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images for O\n",
      "Loading training images for R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 127.91it/s]\n"
     ]
    }
   ],
   "source": [
    "load_train_images(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 500.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 500.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation images for O\n",
      "Loading validation images for R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "load_valid_images(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 40.67it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the testing images for O\n",
      "Loading the testing images for R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 30.03it/s]\n"
     ]
    }
   ],
   "source": [
    "load_test_images(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Faire le train, valider et tester les données à l'aide d'Image Data Loader. J'ai mis à l'échelle chaque pixel de 255 pour que les valeurs d'entrée soient comprises entre 0 et 1, ce qui facilitera l'utilisation de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 images belonging to 2 classes.\n",
      "Found 21 images belonging to 2 classes.\n",
      "Found 31 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1./255)\n",
    "train_batch=ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,rescale=1./255,horizontal_flip=True).flow_from_directory(directory=train_path,target_size=img_size,classes=target,batch_size=batch_size)\n",
    "valid_batch=datagen.flow_from_directory(directory=valid_path,target_size=img_size,classes=target,batch_size=batch_size)\n",
    "test_batch=datagen.flow_from_directory(directory=test_path,target_size=img_size,classes=target,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vérifier si les valeurs de pixels ont été mises à l'échelle ou non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59239614\n"
     ]
    }
   ],
   "source": [
    "images,labels=train_batch.next()\n",
    "print(np.max(images))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Faire une fonction pour définir notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myModel(img):\n",
    "    layer=int(np.log2(img))\n",
    "    model=[]\n",
    "    model+=[\n",
    "        Conv2D(filters=32,kernel_size=(3,3),strides=1,padding='same',input_shape=(img,img,3),activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=32,kernel_size=(3,3),strides=1,padding='same',activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        AvgPool2D(pool_size=(2,2),strides=2),\n",
    "    ]\n",
    "    layer-=1\n",
    "    filters=64\n",
    "    for i in range(layer):\n",
    "        model+=[\n",
    "            Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding='same',activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding='same',activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            AvgPool2D(pool_size=(2,2),strides=2),\n",
    "        ]\n",
    "        filters*=2\n",
    "    model+=[\n",
    "        Flatten(),\n",
    "        Dense(units=4096,activation='relu'),\n",
    "        Dense(units=4096,activation='relu'),\n",
    "        Dense(units=len(target),activation='softmax')\n",
    "    ]\n",
    "    return Sequential(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Créer une fonction pour construire le modèle. Puisque Keras tuner veut une fonction de constructeur et non un modèle. Le (Hyperband, utilisé ici) Tuner lui-même lors de la recherche des paramètres optimaux utilisera le constructeur fourni pour construire plusieurs modèles et les former sur les données et sélectionner la moitié qui fonctionne le mieux et continuer jusqu'à ce qu'il n'en reste qu'un."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=myModel(96)\n",
    "    hp_lr=hp.Choice('learning_rate',values=list(np.linspace(start=0.0001,stop=0.0006,num=12)))\n",
    "    model.compile(optimizer=Adam(lr=hp_lr),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Faire l'objet tuner keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner=kt.Hyperband(build_model,objective='val_accuracy',max_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Faire le signal d'arrêt précoce. Cela arrêtera le modèle si la perte de validation (moniteur) ne s'améliore pas pendant 5 (patience) époques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early=EarlyStopping(monitor='val_loss',patience=5)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Utilisation de la méthode de recherche pour obtenir le taux d'apprentissage optimal (le fait que j'aie attendu 36 minutes pour 0,0001 est tout simplement triste : ( )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_batch,epochs=5,validation_data=valid_batch,callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Obtenir et imprimer les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003727272727272727\n"
     ]
    }
   ],
   "source": [
    "best_hp=best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hp.get('learning_rate'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Construire le modèle avec les meilleurs hyperparamètres que nous avons obtenus de la recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner.hypermodel.build(best_hp)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1250 batches). You may need to use the repeat() function when building your dataset.\n",
      "250/250 - 11s - loss: 0.6787 - accuracy: 0.4634 - val_loss: 0.7022 - val_accuracy: 0.4762\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=train_batch,validation_data=valid_batch,epochs=epochs,steps_per_epoch=steps_per_epoch,verbose=2,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vérification du résultat du modèle sur l'ensemble de test et impression de la précision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.38709677419355\n"
     ]
    }
   ],
   "source": [
    "pre=model.predict(x=test_batch,verbose=0)\n",
    "np.round(pre)\n",
    "cm=confusion_matrix(y_true=test_batch.classes,y_pred=np.argmax(pre,axis=-1))\n",
    "print(f'Accuracy: {(cm.trace()/cm.sum())*100}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Obtenir la précision de l'entraînement et de la validation pour le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy=history.history['val_accuracy']\n",
    "train_accuracy=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracer la précision de la formation et de la validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20006566850>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_accuracy)\n",
    "plt.plot(train_accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Validation accuracy','Training accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
